#!/usr/bin/env python3
"""
DAIC-WOZ Data Exploration Script
Usage: python scripts/explore_data.py
"""

import sys
import os
from pathlib import Path
import pandas as pd
import numpy as np
import yaml
import librosa

# Add src to path for imports
sys.path.append('.')
sys.path.append('./src')

def load_config(config_path: str = "config/data_config.yaml"):
    """Load configuration file"""
    try:
        with open(config_path, 'r') as f:
            return yaml.safe_load(f)
    except FileNotFoundError:
        print(f"âŒ Config file not found: {config_path}")
        return None
    except Exception as e:
        print(f"âŒ Error loading config: {e}")
        return None

def check_data_paths(config):
    """Check if data paths exist and are accessible"""
    print("ğŸ” Checking Data Paths")
    print("=" * 50)
    
    data_root = Path(config['daic_woz']['data_root'])
    data_path = data_root / config['daic_woz']['data_path']
    
    print(f"ğŸ“ Data root: {data_root}")
    print(f"ğŸ“ DAIC-WOZ path: {data_path}")
    print(f"ğŸ“ Data root exists: {data_root.exists()}")
    print(f"ğŸ“ DAIC-WOZ path exists: {data_path.exists()}")
    
    if not data_path.exists():
        print("âŒ DAIC-WOZ data path not found!")
        print("Please check the path in config/data_config.yaml")
        return False
    
    return True, data_path

def check_labels_file(data_path, config):
    """Check labels file (meta_info.csv)"""
    print("\nğŸ“Š Checking Labels File")
    print("=" * 50)
    
    labels_file = data_path / config['labels']['file_path']
    print(f"ğŸ“„ Labels file path: {labels_file}")
    print(f"ğŸ“„ Labels file exists: {labels_file.exists()}")
    
    if not labels_file.exists():
        print("âŒ Labels file not found!")
        return None
    
    try:
        labels_df = pd.read_csv(labels_file)
        print(f"âœ… Labels loaded successfully")
        print(f"ğŸ“Š Shape: {labels_df.shape}")
        print(f"ğŸ“Š Columns: {list(labels_df.columns)}")
        
        # Show first few rows
        print("\nğŸ“‹ First 5 rows:")
        print(labels_df.head())
        
        # Check for depression-related columns
        depression_cols = [col for col in labels_df.columns 
                          if any(keyword in col.lower() for keyword in ['phq', 'depression', 'score'])]
        if depression_cols:
            print(f"\nğŸ¯ Depression-related columns found: {depression_cols}")
            
            # Show value counts for binary labels
            for col in depression_cols:
                if 'binary' in col.lower() or labels_df[col].nunique() <= 5:
                    print(f"\nğŸ“Š {col} value counts:")
                    print(labels_df[col].value_counts())
        
        return labels_df
        
    except Exception as e:
        print(f"âŒ Error reading labels file: {e}")
        return None

def check_participant_folders(data_path, config):
    """Check participant folders and files"""
    print("\nğŸ‘¥ Checking Participant Folders")
    print("=" * 50)
    
    start_id = config['daic_woz']['participant_range']['start']
    end_id = config['daic_woz']['participant_range']['end']
    
    audio_pattern = config['daic_woz']['file_patterns']['audio']
    transcript_pattern = config['daic_woz']['file_patterns']['transcript']
    folder_pattern = config['daic_woz']['folder_pattern']
    
    valid_participants = []
    missing_audio = []
    missing_transcript = []
    
    # Check first 10 participants as sample
    sample_range = range(start_id, min(start_id + 10, end_id + 1))
    
    print(f"ğŸ“‹ Checking sample participants {start_id} to {start_id + 9}:")
    
    for participant_id in sample_range:
        folder_name = folder_pattern.format(participant_id=participant_id)
        participant_folder = data_path / folder_name
        
        audio_name = audio_pattern.format(participant_id=participant_id)
        transcript_name = transcript_pattern.format(participant_id=participant_id)
        
        audio_path = participant_folder / audio_name
        transcript_path = participant_folder / transcript_name
        
        print(f"\nğŸ‘¤ Participant {participant_id}:")
        print(f"   ğŸ“ Folder: {participant_folder.exists()}")
        print(f"   ğŸµ Audio: {audio_path.exists()}")
        print(f"   ğŸ“ Transcript: {transcript_path.exists()}")
        
        if audio_path.exists():
            valid_participants.append(participant_id)
            
            # Check audio file size and duration
            try:
                file_size_mb = audio_path.stat().st_size / (1024 * 1024)
                print(f"   ğŸ“ Audio size: {file_size_mb:.1f} MB")
                
                # Quick duration check (optional, can be slow)
                # duration = librosa.get_duration(filename=str(audio_path))
                # print(f"   â±ï¸  Duration: {duration:.1f} seconds")
                
            except Exception as e:
                print(f"   âš ï¸  Error checking audio: {e}")
        else:
            missing_audio.append(participant_id)
            
        if not transcript_path.exists():
            missing_transcript.append(participant_id)
    
    print(f"\nğŸ“Š Sample Check Summary:")
    print(f"âœ… Valid participants (with audio): {len(valid_participants)}")
    print(f"âŒ Missing audio: {len(missing_audio)}")
    print(f"âŒ Missing transcript: {len(missing_transcript)}")
    
    return valid_participants

def check_full_dataset(data_path, config):
    """Quick check of full dataset"""
    print("\nğŸ” Full Dataset Overview")
    print("=" * 50)
    
    start_id = config['daic_woz']['participant_range']['start']
    end_id = config['daic_woz']['participant_range']['end']
    folder_pattern = config['daic_woz']['folder_pattern']
    audio_pattern = config['daic_woz']['file_patterns']['audio']
    
    total_expected = end_id - start_id + 1
    audio_found = 0
    transcript_found = 0
    
    print(f"ğŸ“Š Expected participants: {total_expected} (ID: {start_id}-{end_id})")
    
    for participant_id in range(start_id, end_id + 1):
        folder_name = folder_pattern.format(participant_id=participant_id)
        participant_folder = data_path / folder_name
        
        if participant_folder.exists():
            audio_name = audio_pattern.format(participant_id=participant_id)
            transcript_name = config['daic_woz']['file_patterns']['transcript'].format(participant_id=participant_id)
            
            if (participant_folder / audio_name).exists():
                audio_found += 1
            if (participant_folder / transcript_name).exists():
                transcript_found += 1
    
    print(f"âœ… Audio files found: {audio_found}/{total_expected}")
    print(f"âœ… Transcript files found: {transcript_found}/{total_expected}")
    print(f"ğŸ“Š Audio coverage: {audio_found/total_expected*100:.1f}%")
    
    return audio_found

def main():
    """Main exploration function"""
    print("ğŸ¯ DAIC-WOZ Data Exploration")
    print("=" * 60)
    
    # Load configuration
    config = load_config()
    if config is None:
        print("âŒ Cannot proceed without configuration")
        return
    
    print("âœ… Configuration loaded successfully")
    
    # Check data paths
    path_check = check_data_paths(config)
    if not path_check[0]:
        return
    
    data_path = path_check[1]
    
    # Check labels file
    labels_df = check_labels_file(data_path, config)
    
    # Check participant folders (sample)
    valid_participants = check_participant_folders(data_path, config)
    
    # Full dataset overview
    total_audio_files = check_full_dataset(data_path, config)
    
    # Final summary
    print("\nğŸ‰ Exploration Summary")
    print("=" * 50)
    
    if labels_df is not None:
        print(f"âœ… Labels file: Available ({len(labels_df)} entries)")
    else:
        print("âŒ Labels file: Not available")
    
    print(f"âœ… Audio files: {total_audio_files} found")
    print(f"âœ… Sample check: {len(valid_participants)} participants verified")
    
    if total_audio_files >= 100:  # Reasonable threshold
        print("\nğŸš€ Ready for feature extraction!")
        print("Next step: python scripts/extract_features.py --test_mode")
    else:
        print("\nâš ï¸  Dataset seems incomplete. Please check data paths.")
        print("You may need to adjust paths in config/data_config.yaml")

if __name__ == "__main__":
    main()
